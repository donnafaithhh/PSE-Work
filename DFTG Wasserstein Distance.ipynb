{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb598822-3ae3-46c9-b9b8-be3c088b3864",
   "metadata": {},
   "source": [
    "## Imports\n",
    "This is for the imports in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "530dc903-b1bb-4ef1-9f8e-14ce6ddb8bfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:20:17.815668Z",
     "iopub.status.busy": "2025-04-19T01:20:17.815448Z",
     "iopub.status.idle": "2025-04-19T01:20:20.757282Z",
     "shell.execute_reply": "2025-04-19T01:20:20.755716Z",
     "shell.execute_reply.started": "2025-04-19T01:20:17.815646Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for choosing random dates\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# for getting the wasserstein distance\n",
    "import itertools\n",
    "import persim\n",
    "import ripser\n",
    "from persim import wasserstein\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# to remove the warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee138fa-30de-454d-a44a-6b8d6733f02a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:20:20.758353Z",
     "iopub.status.busy": "2025-04-19T01:20:20.758017Z",
     "iopub.status.idle": "2025-04-19T01:20:20.762813Z",
     "shell.execute_reply": "2025-04-19T01:20:20.761928Z",
     "shell.execute_reply.started": "2025-04-19T01:20:20.758331Z"
    }
   },
   "outputs": [],
   "source": [
    "directory = r\"matrices\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e67dd04-bed9-42a8-8cf4-b62eaadde071",
   "metadata": {},
   "source": [
    "## Choosing Random Dates\n",
    "This is for choosing random dates within noncrash years before the crash year. The files for these dates have been added to a folder called `test_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82add1fd-3944-4c5f-9eae-b85acae91a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:20:20.764483Z",
     "iopub.status.busy": "2025-04-19T01:20:20.764230Z",
     "iopub.status.idle": "2025-04-19T01:20:20.775087Z",
     "shell.execute_reply": "2025-04-19T01:20:20.773981Z",
     "shell.execute_reply.started": "2025-04-19T01:20:20.764461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-12\n",
      "2016-07-22\n",
      "2017-02-14\n",
      "2017-05-11\n",
      "2018-08-17\n"
     ]
    }
   ],
   "source": [
    "random.seed(1050)\n",
    "start_date = datetime(2013, 11, 1)\n",
    "end_date = datetime(2019, 11, 30)\n",
    "delta = (end_date - start_date).days\n",
    "\n",
    "weekdays = [\n",
    "    start_date + timedelta(days=i)\n",
    "    for i in range((end_date - start_date).days + 1)\n",
    "    if (start_date + timedelta(days=i)).weekday() < 5\n",
    "]\n",
    "\n",
    "random_dates = random.sample(weekdays, 5)\n",
    "\n",
    "for date in sorted(random_dates):\n",
    "    print(date.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375109e-20d9-403c-9b8a-47a7d1f287bb",
   "metadata": {},
   "source": [
    "## Wasserstein distance from ChatGPT\n",
    "This is for getting the Wasserstein distance for the test files. The code was generated by ChatGPT just to see if I can get a code that accurately calculates the Wasserstein distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba345c-9c1b-4870-80f9-44c8ad6fc630",
   "metadata": {},
   "source": [
    "This code uses persim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8831763b-3f19-4321-95d2-ff176d7d6b5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:20:20.775946Z",
     "iopub.status.busy": "2025-04-19T01:20:20.775738Z",
     "iopub.status.idle": "2025-04-19T01:20:20.947140Z",
     "shell.execute_reply": "2025-04-19T01:20:20.946226Z",
     "shell.execute_reply.started": "2025-04-19T01:20:20.775928Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>110 2016-05-12 00_00_00.pickl</th>\n",
       "      <th>110 2016-07-22 00_00_00.pickl</th>\n",
       "      <th>110 2017-02-14 00_00_00.pickl</th>\n",
       "      <th>110 2017-05-11 00_00_00.pickl</th>\n",
       "      <th>110 2018-08-17 00_00_00.pickl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110 2016-05-12 00_00_00.pickl</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.5349</td>\n",
       "      <td>4.2957</td>\n",
       "      <td>5.9091</td>\n",
       "      <td>8.9897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110 2016-07-22 00_00_00.pickl</th>\n",
       "      <td>16.5349</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.8848</td>\n",
       "      <td>21.8747</td>\n",
       "      <td>10.9728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110 2017-02-14 00_00_00.pickl</th>\n",
       "      <td>4.2957</td>\n",
       "      <td>12.8848</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.3582</td>\n",
       "      <td>5.4162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110 2017-05-11 00_00_00.pickl</th>\n",
       "      <td>5.9091</td>\n",
       "      <td>21.8747</td>\n",
       "      <td>9.3582</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.9968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110 2018-08-17 00_00_00.pickl</th>\n",
       "      <td>8.9897</td>\n",
       "      <td>10.9728</td>\n",
       "      <td>5.4162</td>\n",
       "      <td>13.9968</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               110 2016-05-12 00_00_00.pickl  \\\n",
       "110 2016-05-12 00_00_00.pickl                         0.0000   \n",
       "110 2016-07-22 00_00_00.pickl                        16.5349   \n",
       "110 2017-02-14 00_00_00.pickl                         4.2957   \n",
       "110 2017-05-11 00_00_00.pickl                         5.9091   \n",
       "110 2018-08-17 00_00_00.pickl                         8.9897   \n",
       "\n",
       "                               110 2016-07-22 00_00_00.pickl  \\\n",
       "110 2016-05-12 00_00_00.pickl                        16.5349   \n",
       "110 2016-07-22 00_00_00.pickl                         0.0000   \n",
       "110 2017-02-14 00_00_00.pickl                        12.8848   \n",
       "110 2017-05-11 00_00_00.pickl                        21.8747   \n",
       "110 2018-08-17 00_00_00.pickl                        10.9728   \n",
       "\n",
       "                               110 2017-02-14 00_00_00.pickl  \\\n",
       "110 2016-05-12 00_00_00.pickl                         4.2957   \n",
       "110 2016-07-22 00_00_00.pickl                        12.8848   \n",
       "110 2017-02-14 00_00_00.pickl                         0.0000   \n",
       "110 2017-05-11 00_00_00.pickl                         9.3582   \n",
       "110 2018-08-17 00_00_00.pickl                         5.4162   \n",
       "\n",
       "                               110 2017-05-11 00_00_00.pickl  \\\n",
       "110 2016-05-12 00_00_00.pickl                         5.9091   \n",
       "110 2016-07-22 00_00_00.pickl                        21.8747   \n",
       "110 2017-02-14 00_00_00.pickl                         9.3582   \n",
       "110 2017-05-11 00_00_00.pickl                         0.0000   \n",
       "110 2018-08-17 00_00_00.pickl                        13.9968   \n",
       "\n",
       "                               110 2018-08-17 00_00_00.pickl  \n",
       "110 2016-05-12 00_00_00.pickl                         8.9897  \n",
       "110 2016-07-22 00_00_00.pickl                        10.9728  \n",
       "110 2017-02-14 00_00_00.pickl                         5.4162  \n",
       "110 2017-05-11 00_00_00.pickl                        13.9968  \n",
       "110 2018-08-17 00_00_00.pickl                         0.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagrams = []\n",
    "file_names = []\n",
    "\n",
    "for name in sorted(os.listdir(directory)):\n",
    "    file_path = os.path.join(directory, name)\n",
    "    \n",
    "    if os.path.isfile(file_path) and name.endswith('.pickl'):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                dist_matrix = data.get('distance matrix')\n",
    "                if dist_matrix is None:\n",
    "                    print(f\"Distance matrix not found in {name}\")\n",
    "        except (pickle.UnpicklingError, EOFError, KeyError) as e:\n",
    "            print(f\"Error loading {name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "        dgm = ripser.ripser(dist_matrix, distance_matrix=True, maxdim=0)['dgms'][0]\n",
    "        diagrams.append(dgm)\n",
    "        file_names.append(name)\n",
    "        \n",
    "distance_matrix = pd.DataFrame(\n",
    "    0.0, \n",
    "    index=file_names, \n",
    "    columns=file_names\n",
    ")\n",
    "\n",
    "for i in range(len(diagrams)):\n",
    "    for j in range(i, len(diagrams)):\n",
    "        d1 = diagrams[i][~np.isinf(diagrams[i][:, 1])]\n",
    "        d2 = diagrams[j][~np.isinf(diagrams[j][:, 1])]\n",
    "        \n",
    "        dist = wasserstein(d1, d2, matching=False)\n",
    "        distance_matrix.iloc[i, j] = dist\n",
    "        distance_matrix.iloc[j, i] = dist\n",
    "\n",
    "distance_matrix.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc54650-6cc0-4226-832a-55ce6dfacc3a",
   "metadata": {},
   "source": [
    "This code uses the wasserstein_distance function from scipy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bceb4dfd-359d-4e1a-a397-e730bae610eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:20:20.948156Z",
     "iopub.status.busy": "2025-04-19T01:20:20.947946Z",
     "iopub.status.idle": "2025-04-19T01:20:21.007991Z",
     "shell.execute_reply": "2025-04-19T01:20:21.007018Z",
     "shell.execute_reply.started": "2025-04-19T01:20:20.948137Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>110 2016-05-12 00_00_00.pickl</th>\n",
       "      <th>110 2016-07-22 00_00_00.pickl</th>\n",
       "      <th>110 2017-02-14 00_00_00.pickl</th>\n",
       "      <th>110 2017-05-11 00_00_00.pickl</th>\n",
       "      <th>110 2018-08-17 00_00_00.pickl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110 2016-05-12 00_00_00.pickl</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110 2016-07-22 00_00_00.pickl</th>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0699</td>\n",
       "      <td>0.1116</td>\n",
       "      <td>0.0895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110 2017-02-14 00_00_00.pickl</th>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0699</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.0386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110 2017-05-11 00_00_00.pickl</th>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.1116</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110 2018-08-17 00_00_00.pickl</th>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               110 2016-05-12 00_00_00.pickl  \\\n",
       "110 2016-05-12 00_00_00.pickl                         0.0000   \n",
       "110 2016-07-22 00_00_00.pickl                         0.0893   \n",
       "110 2017-02-14 00_00_00.pickl                         0.0244   \n",
       "110 2017-05-11 00_00_00.pickl                         0.0245   \n",
       "110 2018-08-17 00_00_00.pickl                         0.0484   \n",
       "\n",
       "                               110 2016-07-22 00_00_00.pickl  \\\n",
       "110 2016-05-12 00_00_00.pickl                         0.0893   \n",
       "110 2016-07-22 00_00_00.pickl                         0.0000   \n",
       "110 2017-02-14 00_00_00.pickl                         0.0699   \n",
       "110 2017-05-11 00_00_00.pickl                         0.1116   \n",
       "110 2018-08-17 00_00_00.pickl                         0.0895   \n",
       "\n",
       "                               110 2017-02-14 00_00_00.pickl  \\\n",
       "110 2016-05-12 00_00_00.pickl                         0.0244   \n",
       "110 2016-07-22 00_00_00.pickl                         0.0699   \n",
       "110 2017-02-14 00_00_00.pickl                         0.0000   \n",
       "110 2017-05-11 00_00_00.pickl                         0.0441   \n",
       "110 2018-08-17 00_00_00.pickl                         0.0386   \n",
       "\n",
       "                               110 2017-05-11 00_00_00.pickl  \\\n",
       "110 2016-05-12 00_00_00.pickl                         0.0245   \n",
       "110 2016-07-22 00_00_00.pickl                         0.1116   \n",
       "110 2017-02-14 00_00_00.pickl                         0.0441   \n",
       "110 2017-05-11 00_00_00.pickl                         0.0000   \n",
       "110 2018-08-17 00_00_00.pickl                         0.0596   \n",
       "\n",
       "                               110 2018-08-17 00_00_00.pickl  \n",
       "110 2016-05-12 00_00_00.pickl                         0.0484  \n",
       "110 2016-07-22 00_00_00.pickl                         0.0895  \n",
       "110 2017-02-14 00_00_00.pickl                         0.0386  \n",
       "110 2017-05-11 00_00_00.pickl                         0.0596  \n",
       "110 2018-08-17 00_00_00.pickl                         0.0000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagrams = []\n",
    "file_names = []\n",
    "\n",
    "for name in sorted(os.listdir(directory)):\n",
    "    file_path = os.path.join(directory, name)\n",
    "    \n",
    "    if os.path.isfile(file_path) and name.endswith('.pickl'):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                dist_matrix = data.get('distance matrix')\n",
    "                if dist_matrix is None:\n",
    "                    print(f\"Distance matrix not found in {name}\")\n",
    "                    continue\n",
    "        except (pickle.UnpicklingError, EOFError, KeyError) as e:\n",
    "            print(f\"Error loading {name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        dgm = ripser.ripser(dist_matrix, distance_matrix=True, maxdim=0)['dgms'][0]\n",
    "        diagrams.append(dgm)\n",
    "        file_names.append(name)\n",
    "\n",
    "distance_matrix = pd.DataFrame(\n",
    "    0.0, \n",
    "    index=file_names, \n",
    "    columns=file_names\n",
    ")\n",
    "\n",
    "for i in range(len(diagrams)):\n",
    "    for j in range(i, len(diagrams)):\n",
    "        d1 = diagrams[i][~np.isinf(diagrams[i][:, 1])]\n",
    "        d2 = diagrams[j][~np.isinf(diagrams[j][:, 1])]\n",
    "        \n",
    "        lifespan1 = d1[:, 1] - d1[:, 0]\n",
    "        lifespan2 = d2[:, 1] - d2[:, 0]\n",
    "        \n",
    "        dist = wasserstein_distance(lifespan1, lifespan2)\n",
    "        \n",
    "        distance_matrix.iloc[i, j] = dist\n",
    "        distance_matrix.iloc[j, i] = dist\n",
    "\n",
    "distance_matrix.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de344362-5389-46a1-ade6-b4ef2c81aeae",
   "metadata": {},
   "source": [
    "## Wasserstein distance for the test files\n",
    "This is for getting the Wasserstein distance for the test files for the plot for the H0 connected components. If the 5 files are good representatives, their Wasserstein distances should be near zero with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f54d4e-533b-4b9f-bcdb-65aeff2e9e9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:20:21.009064Z",
     "iopub.status.busy": "2025-04-19T01:20:21.008857Z"
    }
   },
   "outputs": [],
   "source": [
    "b0_lists = []\n",
    "file_names = sorted(os.listdir(directory))\n",
    "\n",
    "for name in sorted(os.listdir(directory)):\n",
    "    file_path = os.path.join(directory, name)\n",
    "    \n",
    "    if os.path.isfile(file_path) and name.endswith('.pickl'):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                dist_matrix = data.get('distance matrix')\n",
    "                if dist_matrix is None:\n",
    "                    print(f\"Distance matrix not found in {name}\")\n",
    "        except (pickle.UnpicklingError, EOFError, KeyError) as e:\n",
    "            print(f\"Error loading {name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # making a persistence diagram from a rips filtration \n",
    "    pers_diag = ripser.ripser(dist_matrix, distance_matrix=True, maxdim=2)\n",
    "    diagrams = pers_diag['dgms']\n",
    "    thresh_list = np.linspace(0, 1, 50)\n",
    "    b0_data = []\n",
    "\n",
    "    for t in thresh_list:\n",
    "        pers_diag2 = ripser.ripser(dist_matrix, distance_matrix=True, thresh=t, maxdim=2)\n",
    "        diagrams2 = pers_diag2['dgms']\n",
    "        b0 = sum(d[1] == np.inf for d in diagrams2[0]) if len(diagrams2) > 0 else 0\n",
    "        b0_data.append((t, b0))\n",
    "        \n",
    "    b0_df = pd.DataFrame(b0_data, columns=['threshold', 'b0'])\n",
    "    b0_df['min max'] = (b0_df['b0'] - min(b0_data)[1])/(max(b0_data)[1] - min(b0_data)[1])\n",
    "    \n",
    "    b0_lists.append(b0_df['min max'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c036e-6b43-4221-b1d5-f0c67288b36b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for list in b0_lists:\n",
    "    plt.plot(list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1805b-6c26-48b1-a6c1-09c4549b8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = pd.DataFrame(\n",
    "    0.0, \n",
    "    index=file_names, \n",
    "    columns=file_names\n",
    ")\n",
    "\n",
    "for i in range(len(b0_lists)):\n",
    "    for j in range(i, len(b0_lists)):        \n",
    "        dist = wasserstein_distance(b0_lists[i], b0_lists[j])\n",
    "        \n",
    "        distance_matrix.iloc[i, j] = dist\n",
    "        distance_matrix.iloc[j, i] = dist\n",
    "\n",
    "if '.ipynb_checkpoints' in distance_matrix.index:\n",
    "    distance_matrix = distance_matrix.drop('.ipynb_checkpoints', axis=0)\n",
    "    distance_matrix = distance_matrix.drop('.ipynb_checkpoints', axis=1)\n",
    "\n",
    "distance_matrix.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6903ac-aeda-4a6f-b283-2550d51738c3",
   "metadata": {},
   "source": [
    "Seeing that most of the Wasserstein distances between each are close to zero, then the 5 randomly chosen dates are good representatives of noncrash years prior to the crash year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b961f5b-1067-4a28-a9d8-1c15e85d95b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
